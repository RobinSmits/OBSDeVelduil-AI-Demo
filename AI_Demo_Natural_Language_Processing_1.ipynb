{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Demo - Natural Language Processing 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobinSmits/OBSDeVelduil-AI-Demo/blob/master/AI_Demo_Natural_Language_Processing_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZzA7zcpgNfS",
        "colab_type": "text"
      },
      "source": [
        "# AI Demo - Natural Language Processing 'Is de film recensie positief of negatief?'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5BcQlJZkD0w",
        "colab_type": "text"
      },
      "source": [
        "Hoi! Welkom bij deze demo. \n",
        "\n",
        "In het komende uur gaan we in sneltreinvaart kijken hoe we een computer tekst kunnen leren herkennen. Om specifiek te zijn we gaan de computer leren om op basis van een film recensie aan te geven of deze positief of negatief is.\n",
        "\n",
        "De stappen die we gaan volgen zijn een eenvoudige samenvatting van een zeer uitgebreidde handleiding over dit onderwerp bij Tensorflow. Mocht je de uitgebreide code dus een keer willen doorwerken dan kun je deze vinden op onderstaande link:\n",
        "https://www.tensorflow.org/tutorials/keras/text_classification\n",
        "\n",
        "# Wat gaan we de computer leren?\n",
        "\n",
        "We hebben om de computer tekst te leren herkennen een dataset met veel tekst nodig. We gaan de IMDB Dataset hiervoor gebruiken.\n",
        "\n",
        "De IMDB dataset bevat de tekst van 50000 film recensies. Er zijn film recensies die negatief zijn of die positief zijn.\n",
        "\n",
        "We gaan de computer trainen met 25000 film recensies en vervolgens gaan we kijken of de computer voor een 2de set (de testset) van 25000 recensies voor elke recensie kan voorspellen of deze positief of negatief is.\n",
        "\n",
        "Om de computer iets te leren moeten we een klein computer programma schrijven. Dit computer programma noemen we het 'model'.\n",
        "Zodra we de computer daadwerkelijk gaan laten leren zijn we het 'model' aan het 'trainen'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3AFcx_sCLsp",
        "colab_type": "text"
      },
      "source": [
        "# De start\n",
        "\n",
        "We gaan eerst een aantal Python programma's laden en in gebruik nemen. Deze hebben we nodig om het machine learning model op te zetten en de data te kunnen gebruiken."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnmfTdIxgXq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensorflow is een Artificial Intelligence en Machine Learning programma van Google (Meer weten? https://www.tensorflow.org/learn )\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Met de tensorflow_datasets kunnen we de IMDB dataset straks ophalen\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# Numpy is voor diverse berekeningen. Die hebben we straks ook nodig.\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIF_37ADlmR3",
        "colab_type": "text"
      },
      "source": [
        "# Data verzamelen\n",
        "\n",
        "We gaan de data voor de film recensies downloaden via de eerdere programma's.\n",
        "\n",
        "De dataset is al helemaal voor ons voorbereid. Het belangrijkste is dat alle woorden zijn omgezet naar nummers. En elk nummer verwijst naar het woord in wat ze een vocabulary noemen.\n",
        "\n",
        "Een computer kan niet rechtstreeks met de tekst werken...maar als we de tekst nou op een slimme wijze omzetten naar nummers..dan kan het wel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJU07EtCg19h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We laden de IMDB Dataset\n",
        "(train_data, test_data), info = tfds.load(\n",
        "    # Use the version pre-encoded with an ~8k vocabulary.\n",
        "    'imdb_reviews/subwords8k', \n",
        "    # Return the train/test datasets as a tuple.\n",
        "    split = (tfds.Split.TRAIN, tfds.Split.TEST),\n",
        "    # Return (example, label) pairs from the dataset (instead of a dictionary).\n",
        "    as_supervised=True,\n",
        "    # Also return the `info` structure. \n",
        "    with_info=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J8kYV1GnhrA",
        "colab_type": "text"
      },
      "source": [
        "We kunnen heel makkelijk zien hoe de tekst word omgezet naar een aantal nummers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uof3nDkhH0aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We maken een vertaler aan...die de tekst omzet naar nummers\n",
        "encoder = info.features['text'].encoder\n",
        "\n",
        "# En we zetten een voorbeeld zin om\n",
        "voorbeeld = 'Hallo allemaal. Welkom bij de tekst demo.'\n",
        "voorbeeld_in_nummers = encoder.encode(voorbeeld)\n",
        "print(f'Voorbeeld in nummers: {voorbeeld_in_nummers}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91d4TkMbnnpq",
        "colab_type": "text"
      },
      "source": [
        "Of nu met de losse woorden...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD7z1SGyqYv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Hallo = {encoder.encode(\"Hallo\")}')\n",
        "print(f'Hallo = {encoder.encode(\"Hallo \")}')\n",
        "print(f'allemaal. = {encoder.encode(\"allemaal.\")}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_YtMWGhq_RA",
        "colab_type": "text"
      },
      "source": [
        "En wat we zien is dat 1 woord toch meerdere nummers kan opleveren. Wat de encoder doet is bijvoorbeeld het einde van de zin of een spatie aangeven. Ook worden woorden wel eens opgesplitst.\n",
        "\n",
        "Kijk maar :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vs5yhpfrYDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'4313 = \"{encoder.decode([4313])}\"')\n",
        "print(f'8040 = \"{encoder.decode([8040])}\"')\n",
        "print(f'222  = \"{encoder.decode([222])}\"')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk_CuGtUuZnH",
        "colab_type": "text"
      },
      "source": [
        "Laten we nog even een 2 tal voorbeelden uit de IMDB dataset bekijken.\n",
        "\n",
        "Voor elk voorbeeld laten we de volledig tekst in nummers, de tekst zelf en het label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usd22ZPitgHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for train_example, train_label in train_data.take(2):\n",
        "  print('Tekst nummers:', train_example.numpy())\n",
        "  print('Tekst:', encoder.decode(train_example))\n",
        "  print('Label:', train_label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojykyRfZu_AA",
        "colab_type": "text"
      },
      "source": [
        "We doen nu even de laatste paar stappen om de data voor te bereiden.\n",
        "\n",
        "We bereidden de trainings data voor waarmee we het model trainen en de tekst leren te herkennen.\n",
        "\n",
        "En we bereidden de test data voor waarmee we het model straks testen en kijken hoe goed we voor onbekende film recensies kunen voorspellen of deze positief of negatief zijn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09jxIjF6xLmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 1000\n",
        "train_batches = (train_data.shuffle(BUFFER_SIZE).padded_batch(32))\n",
        "test_batches = (test_data.padded_batch(32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BedFA_GYKEIp",
        "colab_type": "text"
      },
      "source": [
        "We gaan nu een simpel model opzetten met behulp van een programma genaamd 'Tensorflow'. Met Tensorflow kun je eenvoudige modellen zoals we hierna gaan doen maken tot de meest complexe AI systemen denkbaar.\n",
        "\n",
        "Wat we in het model stoppen zijn de reeksen met cijfers die de woorden voorstellen. Wat we voorspellen is of de recensie negatief (0) of positief (1) is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBT-g7SEg6ZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "  keras.layers.Embedding(encoder.vocab_size, 16),\n",
        "  keras.layers.GlobalAveragePooling1D(),\n",
        "  keras.layers.Dense(1, activation='sigmoid')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGA09G2q9zIt",
        "colab_type": "text"
      },
      "source": [
        "We kunnen heel simpel bekijken hoe ons model er uitziet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3hX8zeRhHcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPS2zRJnAbgV",
        "colab_type": "text"
      },
      "source": [
        "# Model Trainen\n",
        "\n",
        "We gaan nu ons model trainen door het 10 keer alle film recensies te laten 'lezen'. En elke keer wordt erbij getoond (met het label!) of deze recensie positief of negatief was.\n",
        "\n",
        "Het model gaat dan leren bijvoorbeeld of er bepaalde woorden of zinnen gebruikt worden voor een positieve of negatieve recensie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOUH9KnOh9tP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deze regels zijn nodig om het model compleet te maken..\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
        "\n",
        "# Als je zelf wat wilt spelen met hoe het model leert...\n",
        "# Je kan de learning_rate bijvoorbeel groter of kleiner maken.\n",
        "# Als je hem kleiner maakt duurt het leren langer.\n",
        "# Als je hem groter maakt leert hij sneller en het kan zelfs zijn dat hij slechter leert.\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "\n",
        "# We 'compileren' ==> 'gereed maken' het model met zijn optimizer, loss en metrics\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])\n",
        "\n",
        "# Hier starten we het trainen van het model\n",
        "model.fit(train_batches,\n",
        "          epochs = 10,\n",
        "          validation_data = test_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPsFBJDpB_Tb",
        "colab_type": "text"
      },
      "source": [
        "We hebben nu ons model getrained. De getallen aan de rechterkant ('loss' en 'accuracy') geven aan het goed het model is getrained.\n",
        "\n",
        "De 'loss' willen we altijd zo laag mogelijk (richting 0 krijgen) en de 'accuracy' zo hoog mogelijk (richting 1)\n",
        "\n",
        "We kunnen ons model nu testen. Laten we eens kijken hoe goed (of misschien wel slecht??) het model is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hwfk1Y5EhuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test het model\n",
        "loss, accuracy = model.evaluate(test_batches)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIbfY2nmEzpU",
        "colab_type": "text"
      },
      "source": [
        "We zien dat ons model ongeveer rond de 85% a 86% juist een voorspelling maakt.\n",
        "\n",
        "Ik ben benieuwd of we nog hoger kunnen scoren...laten we nog een 2de model proberen wat net iets beter kan leren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puEaAYhHFT15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model 2\n",
        "model2 = keras.Sequential([\n",
        "  keras.layers.Embedding(encoder.vocab_size, 16),\n",
        "  keras.layers.GlobalAveragePooling1D(),\n",
        "  keras.layers.Dense(32, activation='relu'),\n",
        "  keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "# Samenvatting van Model 2\n",
        "model2.summary()\n",
        "\n",
        "# Deze regels zijn nodig om het model compleet te maken..\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0005)\n",
        "\n",
        "# We 'compileren' ==> 'gereed maken' het model met zijn optimizer, loss en metrics\n",
        "model2.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])\n",
        "\n",
        "# Hier starten we het trainen van het 2de model\n",
        "model2.fit(train_batches,\n",
        "          epochs = 10,\n",
        "          validation_data = test_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ONu2tG1HCVF",
        "colab_type": "text"
      },
      "source": [
        "En als we nu weer ons model testen...zullen we zien dat het net iets beter scored dan het eerste model.\n",
        "\n",
        "Doordat we het model hebben uitgebreid kan het als het ware meer dingen leren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-myTzcOF8mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test het Model 2\n",
        "loss, accuracy = model2.evaluate(test_batches)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsaCkLxYODA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Los voorbeeld tekst.\n",
        "voorbeeld_in_nummers = encoder.encode('This was probably the most terrible movie.. a complete disaster')\n",
        "print(model2.predict([voorbeeld_in_nummers]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}